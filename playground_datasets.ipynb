{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menu Logic\n",
    "basically:\n",
    "- option 1:\n",
    "train model\n",
    "display accuracy on test dataset\n",
    "save model\n",
    "\n",
    "- option 2:\n",
    "load model (if not trained = error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notes*\n",
    "\n",
    "some of the algorithm are brute forced, and will be revisited again for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "\n",
    "# will load the dataset \n",
    "def get_dataset(parent_path):\n",
    "    train_image = []\n",
    "    train_label = []\n",
    "\n",
    "    test_image = \n",
    "\n",
    "    image_count = []\n",
    "    # idx -> \n",
    "    for idx, label in enumerate(os.listdir(parent_path)):\n",
    "        image_path = os.path.join(parent_path, label)\n",
    "        count = 0\n",
    "        for images in os.listdir(image_path):\n",
    "            # read from path\n",
    "            path2 = os.path.join(image_path, images)\n",
    "            gray_img = cv2.imread(path2, 0) # read as grayscale\n",
    "            \n",
    "            image_datasets.append(gray_img)\n",
    "            label_datasets.append(idx)\n",
    "            count += 1\n",
    "        image_count.append(count)\n",
    "    # this will return the image path & its label in order from the datasets\n",
    "    return image_datasets, label_datasets, image_count\n",
    "\n",
    "\n",
    "## splitting into train, test\n",
    "def split_datasets(images, labels, label_count):\n",
    "    test_image = []\n",
    "    test_label = []\n",
    "    popped = 0 # berapa banyak image yang di pop (dimasukin test dataset)\n",
    "\n",
    "    for idx, x in enumerate(label_count):\n",
    "        # ini 25% dari banyak foto\n",
    "        random_num = random.sample(range(0, x), quarter_label_size) # get 5 unique number from 0 -> num of images\n",
    "        \n",
    "        random_num.sort() # ini perlu di sort buat gampangin pop\n",
    "\n",
    "        min = x*idx-popped # starting index of i'th class\n",
    "        # take\n",
    "        for i in random_num:\n",
    "            test_image.append(images[i+min])\n",
    "            test_label.append(labels[i+min])\n",
    "        # pop\n",
    "        for counter, j in enumerate(random_num):\n",
    "            images.pop(j+min-counter)\n",
    "            labels.pop(j+min-counter)\n",
    "\n",
    "        popped += quarter_label_size # keep track of popped images\n",
    "        \n",
    "    return images, labels, test_image, test_label        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROBLEMS in split_datasets:\n",
    "- index out of bound while popping the list\n",
    "case 1:\n",
    "```\n",
    "index_to_pop = (4, 9, 3, 2, 7)\n",
    "image_list = (0.a, 1.b, 2.c, 3.d, 4.e, 5.f, 6.g, 7.h, 8.i, 9.j) -> (idx.value)\n",
    "first iter curr list = (0.a, 1.b, 2.c, 3.d, 4.e, 5.f, 6.g, 7.h, 8.i, 9.j)\n",
    "    images.pop[4]\n",
    "    (target = e | popped = e)\n",
    "\n",
    "second iter curr list = (0.a, 1.b, 2.c, 3.d, 4.f, 5.g, 6.h, 7.i, 8.j) \n",
    "    images.pop[9-0]\n",
    "    (target = j | popped = ?) -> error (max index = 8)\n",
    "```\n",
    "tried:\n",
    "- implementing counter -> if one data is popped, then the index will-1 (counter). since i dont change the true value (i just pop through the index), the counter must increase each time. (problem solved)\n",
    "\n",
    "#### Implementing counter causes:\n",
    "case 2:\n",
    "```\n",
    "index_to_pop = (4, 9, 3, 2, 7)\n",
    "image_list = (0.a, 1.b, 2.c, 3.d, 4.e, 5.f, 6.g, 7.h, 8.i, 9.j) -> (idx.value)\n",
    "first iter (counter=0) curr list = (0.a, 1.b, 2.c, 3.d, 4.e, 5.f, 6.g, 7.h, 8.i, 9.j)\n",
    "    images.pop[4-0]\n",
    "    (target = e | popped = e)\n",
    "\n",
    "second iter (counter=1) curr list = (0.a, 1.b, 2.c, 3.d, 4.f, 5.g, 6.h, 7.i, 8.j)\n",
    "    images.pop[9-1]\n",
    "    (target = j | popped = j)\n",
    "\n",
    "third iter (counter=2) curr list = (0.a, 1.b, 2.c, 3.d, 4.f, 5.g, 6.h, 7.i)\n",
    "    images.pop[3-2]\n",
    "    (target = d | popped = b) -> logic error\n",
    "```\n",
    "hencewhy I added \"random_num.sort()\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 - 200\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"Dataset\"\n",
    "image_datasets, label_datasets, num = get_dataset(dataset_path)\n",
    "print(f\"{len(image_datasets)} - {len(label_datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to-test:\n",
    "+ resize => must\n",
    "+ image augmentation => high\n",
    "\n",
    "+ detect face then crop -> into square (use haar cascade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (if needed):\n",
    "- /255 regularization\n",
    "- find max widht & max height\n",
    "- change label to hot encoded\n",
    "\n",
    "(if needed)\n",
    "- image augmentation \n",
    "- change channel size to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max height & width in picture\n",
    "def find_max_image(image_dataset):\n",
    "    max_height = 0\n",
    "    max_width = 0\n",
    "    for gambar in image_dataset:\n",
    "        temp_height = gambar.shape[0]\n",
    "        temp_width = gambar.shape[1]\n",
    "\n",
    "        if temp_width > max_width:\n",
    "            max_width = temp_width\n",
    "        if temp_height > max_height:\n",
    "            max_height = temp_height\n",
    "    return max_height, max_width\n",
    "\n",
    "# find min height & width\n",
    "def find_min_image(image_dataset):\n",
    "    min_height = 99999999\n",
    "    min_width = 99999999\n",
    "    for gambar in image_dataset:\n",
    "        temp_height = gambar.shape[0]\n",
    "        temp_width = gambar.shape[1]\n",
    "\n",
    "        if temp_width < min_width:\n",
    "            min_width = temp_width\n",
    "        if temp_height < min_height:\n",
    "            min_height = temp_height\n",
    "    return min_height, min_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842, 474\n"
     ]
    }
   ],
   "source": [
    "max_height, max_width = find_max_image(image_datasets)\n",
    "min_h, min_w = find_min_image(image_datasets)\n",
    "print(f\"{max_height}, {max_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect face (can use haar cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detect face\n",
    "def detect_face():\n",
    "    print(\"Hwllo\")\n",
    "\n",
    "def draw_bounding_accuracy():\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## full padding -> resourcely expensive (kinda brute forcing)\n",
    "def pad_image(image, desired_height, desired_width):\n",
    "    height, width, dim = image.shape\n",
    "    top = int((desired_height-height)/2)\n",
    "    left = int((desired_width-width)/2)\n",
    "    down = top\n",
    "    right = left\n",
    "\n",
    "    if (height % 2 == 1):\n",
    "        down+=1\n",
    "    if (width % 2 == 1):\n",
    "        right+=1\n",
    "\n",
    "    padded = np.pad(image, ((top, down), (left, right), (0, 0)), constant_values=0)\n",
    "\n",
    "    return padded\n",
    "\n",
    "def iterate_for_pad(images, desired_height, desired_width):\n",
    "    padded_list = []\n",
    "    for x in images:\n",
    "        padded_list.append(pad_image(x, desired_height, desired_width))\n",
    "    \n",
    "    return padded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_images = iterate_for_pad(image_datasets, max_height, max_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label, test_image, test_label = split_datasets(padded_images, label_datasets, num)\n",
    "train_image = np.array(train_image)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(842, 474, 3)\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASS = len(os.listdir(dataset_path))\n",
    "INPUT_SHAPE = train_image[0].shape\n",
    "print(INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = to_categorical(train_label, NUM_CLASS)\n",
    "test_label = to_categorical(test_label, NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # input layer\n",
    "    layers.Input(shape=INPUT_SHAPE),\n",
    "    # convolutional & pooling\n",
    "    layers.Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\"),\n",
    "    layers.MaxPool2D(2,2),\n",
    "    # flatten\n",
    "    layers.Flatten(),\n",
    "    # output\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(NUM_CLASS, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# adam (learning rate)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "## ini training\n",
    "history = model.fit(\n",
    "    train_image,\n",
    "    train_label,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_image, test_label, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss: {loss}, acc: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
